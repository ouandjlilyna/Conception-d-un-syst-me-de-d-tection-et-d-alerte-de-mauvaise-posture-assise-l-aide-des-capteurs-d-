# -*- coding: utf-8 -*-
"""Multiclasse.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oy9c2lzOIBIzL8D8yzbfJorbJHm_Tc0n
"""

import numpy as np 
import pandas as pd

!mkdir -p dataset/positive
!mkdir -p dataset/negative
#!mkdir -p dataset/Arriere
!mkdir -p dataset/Agauche
!mkdir -p dataset/Adroite

##################"multiclasse"####################
import os
import glob
import seaborn as sns
import matplotlib.pyplot as plt

path_dataset_positive = os.getcwd() + (r'/dataset/positive')
path_dataset_negative = os.getcwd() + (r'/dataset/negative')
#path_dataset_Arriere = os.getcwd() + (r'/dataset/Arriere')
path_dataset_Agauche = os.getcwd() + (r'/dataset/Agauche')
path_dataset_Adroite = os.getcwd() + (r'/dataset/Adroite')




csv_files_Bonne = glob.glob(os.path.join(path_dataset_positive, "*.csv"))
csv_files_Avant = glob.glob(os.path.join(path_dataset_negative, "*.csv"))
#csv_files_Arriere = glob.glob(os.path.join(path_dataset_Arriere, "*.csv"))
csv_files_Agauche = glob.glob(os.path.join(path_dataset_Agauche, "*.csv"))
csv_files_Adroite = glob.glob(os.path.join(path_dataset_Adroite, "*.csv"))




max_B = []
min_B = []
mean_B = []
std_B = []
var_B = []
age_B = []
gender_B =[]

max_M_Av = []
min_M_Av = []
mean_M_Av = []
std_M_Av = []
var_M_Av = []
age_M_Av = []
gender_M_Av =[]

#max_M_Ar = []
#min_M_Ar = []
#mean_M_Ar = []
#std_M_Ar = []
#var_M_Ar = []

max_M_Ad = []
min_M_Ad = []
mean_M_Ad = []
std_M_Ad = []
var_M_Ad = []
age_M_Ad = []
gender_M_Ad =[]

max_M_Ag = []
min_M_Ag = []
mean_M_Ag = []
std_M_Ag = []
var_M_Ag = []
age_M_Ag = []
gender_M_Ag =[]



# loop over the list of csv files
x=0
def print_stat_data(directory, x):
  for f in directory:

      df = pd.read_csv(f)

      max = df['data'].max()
      min = df['data'].min()
      mean = df['data'].mean()
      std = df['data'].std() 
      var = df['data'].var()
      age = df['age'].values[0].astype(int)
      gender = df['gender'].values[0].astype(int)

      
      if x == 0:
        
        max_B.append(max)
        min_B.append(min)
        mean_B.append(mean)
        std_B.append(std)
        var_B.append(var)
        age_B.append(age)
        gender_B.append(gender)
        

      elif x == 1:
        
        max_M_Av.append(max)
        min_M_Av.append(min)
        mean_M_Av.append(mean)
        std_M_Av.append(std)
        var_M_Av.append(var)
        age_M_Av.append(age)
        gender_M_Av.append(gender)

      #elif x == 2:
       
        #max_M_Ar.append(max)
        #min_M_Ar.append(min)
        #mean_M_Ar.append(mean)
        #std_M_Ar.append(std)
        #var_M_Ar.append(var)

      elif x == 2:
       
        max_M_Ad.append(max)
        min_M_Ad.append(min)
        mean_M_Ad.append(mean)
        std_M_Ad.append(std)
        var_M_Ad.append(var)
        age_M_Ad.append(age)
        gender_M_Ad.append(gender)


      else :
       
        max_M_Ag.append(max)
        min_M_Ag.append(min)
        mean_M_Ag.append(mean)
        std_M_Ag.append(std)
        var_M_Ag.append(var)
        age_M_Ag.append(age)
        gender_M_Ag.append(gender)
      


      print(f"|  {max}     {min}    {mean}     {std}     {var}     {age}      {gender} " )
      
print('---------------------------------------------------------------------------------------------------------------------------------------------')
print(' Bonne Posture \n')
print(f"|  max     min    mean                 std                    var              age       gender " )
print_stat_data(csv_files_Bonne,0)
#print(plus)
print('---------------------------------------------------------------------------------------------------------------------------------------------')
print(' inclinaison vers l avant\n')
print(f"|  max     min    mean                 std                    var              age       gender " )
print_stat_data(csv_files_Avant,1)

print('---------------------------------------------------------------------------------------------------------------------------------------------')
#print('Arriere')
#print_stat_data(csv_files_Arriere,2)


print(' inclinaison vers l adroite\n')
print(f"|  max     min    mean                 std                    var              age       gender " )
print_stat_data(csv_files_Adroite,2)
print('---------------------------------------------------------------------------------------------------------------------------------------------')

print(' inclinaison vers l agauche\n')
print(f"|  max     min    mean                 std                    var              age       gender " )
print_stat_data(csv_files_Agauche,3)
print('---------------------------------------------------------------------------------------------------------------------------------------------')

from sklearn.linear_model import SGDClassifier
from sklearn.datasets import load_iris
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.preprocessing import scale

##################"multiclasse"####################
X = []
Y = []
for (max, min, mean, std, pos, age, gender) in zip(max_B, min_B, mean_B, std_B, var_B, age_B, gender_B):
     X.append([max, min, mean, std, pos, age, gender])
     Y.append(0)

for (max, min, mean, std, pos, age, gender) in zip(max_M_Av, min_M_Av, mean_M_Av, std_M_Av, var_M_Av, age_M_Av, gender_M_Av):
     X.append([max, min, mean, std, pos, age, gender])
     Y.append(1)

#for (max, min, mean, std, pos) in zip(max_M_Ar, min_M_Ar, mean_M_Ar, std_M_Ar, var_M_Ar):
    # X.append([max, min, mean, std, pos])
    # Y.append(2)

for (max, min, mean, std, pos, age, gender) in zip(max_M_Ad, min_M_Ad, mean_M_Ad, std_M_Ad, var_M_Ad, age_M_Ad, gender_M_Ad):
     X.append([max, min, mean, std, pos, age, gender])
     Y.append(2)

for (max, min, mean, std, pos, age, gender) in zip(max_M_Ag, min_M_Ag, mean_M_Ag, std_M_Ag, var_M_Ag, age_M_Ad, gender_M_Ad):
     X.append([max, min, mean, std, pos, age, gender])
     Y.append(3)

from sklearn.metrics import accuracy_score

xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 0.20)

from sklearn.svm import SVC


import numpy as np
import matplotlib.pyplot as plt
import time
svc = SVC() 
start = time.time()

kernel_list=['linear', 'poly', 'rbf', 'sigmoid']
train_accuracy = [] # Log training errors for each model
test_accuracy = [] # Log testing errors for each model

for x in kernel_list:
    svcc =SVC(kernel=x) 
    svcc.fit(xtrain,ytrain)
    train_z = svcc.predict(xtrain)
    test_z = svcc.predict(xtest)
    train_accuracy.append(accuracy_score(ytrain, train_z))
    test_accuracy.append(accuracy_score(ytest, test_z))

end = time.time()
runtime=end-start


print(f'Temps d\'exécution :  {runtime:.2} ms')
x = np.arange(len(kernel_list)) + 1 # Create domain for plot
plt.plot(x, train_accuracy, label='Training accuracy ') # Plot training accuracy
plt.plot(x, test_accuracy, label='Testing accuracy') # Plot testing accuracy
plt.xlabel('kernel: linear, poly, rbf, sigmoid') # Label x-axis
plt.ylabel('Total accuracy') # Label y-axis
plt.legend() # Show plot labels as legend
plt.show() # Show graph

import numpy as np
import matplotlib.pyplot as plt
import time
from sklearn.svm import SVC
svc = SVC() 
start = time.time()
x='sigmoid'
svcc =SVC(kernel=x) 
svcc.fit(xtrain,ytrain)
train_z = svcc.predict(xtrain)
test_z = svcc.predict(xtest)
test_accuracy=accuracy_score(ytest, test_z)
train_accuracy=accuracy_score(ytrain, train_z)
print(f'test accuracy :  {test_accuracy:.2} ') 
print(f'train accuracy :  {train_accuracy:.2} ') 

end = time.time()
runtime=end-start


print(f'Temps d\'exécution SVM :  {runtime} ms')

import numpy as np
import matplotlib.pyplot as plt
import time
from sklearn.neighbors import KNeighborsClassifier
start = time.time()
    
k_list=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,28,30]
train_accuracy = [] 
test_accuracy = [] 

for x in k_list:
    knnn =KNeighborsClassifier(n_neighbors=x) 
    knnn.fit(xtrain,ytrain)
    train_z = knnn.predict(xtrain)
    test_z = knnn.predict(xtest)
    train_accuracy.append(accuracy_score(ytrain, train_z))
    test_accuracy.append(accuracy_score(ytest, test_z))

   
end = time.time()
runtime=end-start


print(f'Temps d\'exécution :  {runtime:.2} ms')




x = np.arange(len(k_list)) + 1 # Create domain for plot
plt.plot(x, train_accuracy, label='Training accuracy ') # Plot training accuracy over domain
plt.plot(x, test_accuracy, label='Testing accuracy ') # Plot testing accuracy over domain
plt.xlabel('Value of K for KNN') # Label x-axis
plt.ylabel('Total accuracy') # Label y-axis
plt.legend() # Show plot labels as legend
plt.show() # Show graph

import numpy as np
import matplotlib.pyplot as plt
import time
from sklearn.neighbors import KNeighborsClassifier
start = time.time()
    
 
knnn=KNeighborsClassifier(n_neighbors=8) 
knnn.fit(xtrain,ytrain)
train_z = knnn.predict(xtrain)
test_z = knnn.predict(xtest)
train_accuracy= accuracy_score(ytrain, train_z)
test_accuracy= accuracy_score(ytest, test_z)

print(f'test accuracy :  {test_accuracy:.2} ') 
print(f'train accuracy :  {train_accuracy:.2} ') 
   
end = time.time()
runtime=end-start


print(f'Temps d\'exécution KNN :  {runtime:.2} ms')

from sklearn.tree import DecisionTreeClassifier
import numpy as np
import matplotlib.pyplot as plt
import time
max_depth_list = [1,2,3,4,5,6,7,8,9,10]

train_accuracy = [] 
test_accuracy = []  
start = time.time()
for x in max_depth_list:
    dtc = DecisionTreeClassifier(max_depth=x,random_state=0) 
    dtc.fit(xtrain,ytrain)
    train_z = dtc.predict(xtrain)
    test_z = dtc.predict(xtest)
    train_accuracy.append(accuracy_score(ytrain, train_z))
    test_accuracy.append(accuracy_score(ytest, test_z))
end = time.time()
runtime=end-start


print(f'Temps d\'exécution :  {runtime:.2} ms')

x = np.arange(len(max_depth_list)) + 1 # Create domain for plot
plt.plot(x, train_accuracy, label='Training Accuracy') 
plt.plot(x, test_accuracy, label='Testing Accuracy') 
plt.xlabel('Maximum Depth') # Label x-axis
plt.ylabel('Total accuracy') # Label y-axis
plt.legend() # Show plot labels as legend
plt.show() # Show graph

from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
decision_tree = DecisionTreeClassifier(random_state=0, max_depth=1)
decision_tree = decision_tree.fit(xtrain, ytrain)
import time

start = time.time()
scrrrr = decision_tree.score(xtest, ytest)
print("Training score decision_tree : ", scrrrr)

y_predd = decision_tree.predict(xtrain)
y_pred = decision_tree.predict(xtest)
test_accuracy=accuracy_score(ytest, test_z)
train_accuracy=accuracy_score(ytrain, train_z)
print(' test Accuracy : {:.2f}'.format(accuracy_score(ytest, y_pred)))
print(' train Accuracy: {:.2f}'.format(accuracy_score(ytrain, y_predd)))

end = time.time()
runtime=end-start


print(f'Temps d\'exécution DT :  {runtime:.2} ms')

tree.plot_tree(decision_tree)

from sklearn.ensemble import RandomForestClassifier
import numpy as np
import matplotlib.pyplot as plt
import time
start = time.time()

n_estimators_list= [1,2,3,4,5,6,7,8,9,10]
train_accuracy = [] 
test_accuracy = [] 

for x in n_estimators_list:
    rfc = RandomForestClassifier(n_estimators=x,random_state=0) 
    rfc.fit(xtrain,ytrain)
    train_z = rfc.predict(xtrain)
    test_z = rfc.predict(xtest)
    train_accuracy.append(accuracy_score(ytrain, train_z))
    test_accuracy.append(accuracy_score(ytest, test_z))

end = time.time()
runtime=end-start

print(f'Temps d\'exécution :  {runtime:.2} ms')

x = np.arange(len(n_estimators_list)) + 1 # Create domain for plot
plt.plot(x, train_accuracy, label='Training accuracy')
plt.plot(x, test_accuracy, label='Testing accuracy')
plt.xlabel(' number of trees in the forest') # Label x-axis
plt.ylabel('Total accuracy') # Label y-axis
plt.legend() # Show plot labels as legend
plt.show() # Show grap

from sklearn.ensemble import RandomForestClassifier
import numpy as np
import matplotlib.pyplot as plt
import time
start = time.time()




rfc = RandomForestClassifier(n_estimators=6,random_state=0) 
rfc.fit(xtrain,ytrain)
train_z = rfc.predict(xtrain)
test_z = rfc.predict(xtest)
train_accuracy= accuracy_score(ytrain, train_z)
test_accuracy= accuracy_score(ytest, test_z)
print(f'test accuracy :  {test_accuracy:.2} ') 
print(f'train accuracy :  {train_accuracy:.2} ')    

end = time.time()
runtime=end-start

print(f'Temps d\'exécution :  {runtime:.2} ms')

import pandas as pd

plotdata = pd.DataFrame(
    {"Testing accuracy %": [50, 57, 50, 50], 
     "Ttraining accuracy %": [73, 71, 89, 96]}, 
    index=["SVM", "KNN", "DT", "RF"])
# Plot a bar chart
plotdata.plot(kind="bar",title='Accuracy Comparison for multiclasse classification with ML')

import pandas as pd
#LE CAS OU TEST 30 POURCENT SVM2 KNN2 DT2 RF2
plotdata = pd.DataFrame(
    {"Testing accuracy %": [48, 38, 52, 38,57], 
     "Ttraining accuracy %": [53, 71, 57, 86,48]}, 
    index=["SVM", "KNN", "DT", "RF","MLP"])
# Plot a bar chart
plotdata.plot(kind="bar",title='Accuracy Comparison for multiclasse classification ')

import pandas as pd
#LE CAS OU TEST 20 POURCENT SVMMUL KNNMUL DTMUL RFMUL
plotdata = pd.DataFrame(
    {"Training accuracy %": [59, 77, 76, 96,59], 
     "Testing accuracy %": [57, 68, 68, 71,56]}, 
    index=["SVM", "KNN", "DT", "RF","MLP"])
# Plot a bar chart
plotdata.plot(kind="bar",title='Accuracy Comparison for multiclasse classification ')
from matplotlib import pyplot as plt


plt.ylabel('accuracy')
plt.xlabel('models')
plt.legend(['Train', 'test'], loc='upper left')
plt.show()

xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 0.20)

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os, sys







ytrain = keras.utils.to_categorical(ytrain,num_classes=4)

ytest = keras.utils.to_categorical(ytest,num_classes=4)

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os, sys


def get_model_v1():
  model = keras.models.Sequential()
  #model.add(keras.layers.Input(shape,name="Input"))
  tf.keras.Sequential([tf.keras.Input(shape=(7,)), tf.keras.layers.Dense(7) ])
  model.add(keras.layers.Dense(40,activation='tanh', name= 'Dense_n1'))

  model.add(keras.layers.Dense(4,activation='softmax',name='Output'))
  model.compile(optimizer='Adam' ,
              loss='categorical_crossentropy' ,
              metrics= ['accuracy'] )
  return model

model= get_model_v1()
#model.summary()

xtrain, ytrain = np.array(xtrain), np.array(ytrain)
xtest, ytest= np.array(xtest),np.array(ytest)

results= model.fit(xtrain,
                  ytrain,
                  epochs          =100,
                  batch_size      =1,  
                   
                   
                  validation_data = (xtest, ytest)
                   )

print("Test-Accuracy:", np.mean(results.history["val_accuracy"]))
print("Accuracy:", np.mean(results.history["accuracy"]))
print("loss:", np.mean(results.history["loss"]))

from matplotlib import pyplot as plt
plt.plot(results.history['accuracy'])
plt.plot(results.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['Train', 'test'], loc='lower right')
plt.show()

plt.plot(results.history['loss'])
plt.plot(results.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('epoch')
plt.legend(['Train', 'test'], loc='center right')
plt.show()